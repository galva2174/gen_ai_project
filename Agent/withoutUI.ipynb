{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMMNa0Rgz4YL0usW8ZJWSMf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install pinecone"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bGTW8HejoZmK","executionInfo":{"status":"ok","timestamp":1743666665676,"user_tz":-330,"elapsed":9760,"user":{"displayName":"Mohul YP","userId":"12458545381722168229"}},"outputId":"4881cb95-d13c-4d2e-a8fe-b9e61d290b89"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pinecone\n","  Downloading pinecone-6.0.2-py3-none-any.whl.metadata (9.0 kB)\n","Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.11/dist-packages (from pinecone) (2025.1.31)\n","Collecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone)\n","  Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\n","Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from pinecone) (2.8.2)\n","Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from pinecone) (4.13.0)\n","Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from pinecone) (2.3.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.5.3->pinecone) (1.17.0)\n","Downloading pinecone-6.0.2-py3-none-any.whl (421 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m421.9/421.9 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n","Installing collected packages: pinecone-plugin-interface, pinecone\n","Successfully installed pinecone-6.0.2 pinecone-plugin-interface-0.0.7\n"]}]},{"cell_type":"code","source":["!pip install groq youtube-transcript-api"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sSBFbFlYodG_","executionInfo":{"status":"ok","timestamp":1743666703276,"user_tz":-330,"elapsed":3585,"user":{"displayName":"Mohul YP","userId":"12458545381722168229"}},"outputId":"718645aa-f960-4346-b260-95fbe0d3b8d2"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting groq\n","  Downloading groq-0.22.0-py3-none-any.whl.metadata (15 kB)\n","Collecting youtube-transcript-api\n","  Downloading youtube_transcript_api-1.0.3-py3-none-any.whl.metadata (23 kB)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (4.9.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.11.0)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n","Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.13.0)\n","Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from youtube-transcript-api) (0.7.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from youtube-transcript-api) (2.32.3)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2025.1.31)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.33.0)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (3.4.1)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (2.3.0)\n","Downloading groq-0.22.0-py3-none-any.whl (126 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.7/126.7 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading youtube_transcript_api-1.0.3-py3-none-any.whl (2.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: youtube-transcript-api, groq\n","Successfully installed groq-0.22.0 youtube-transcript-api-1.0.3\n"]}]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7NsN7q2Ce1dn","executionInfo":{"status":"ok","timestamp":1743666934636,"user_tz":-330,"elapsed":7511,"user":{"displayName":"Mohul YP","userId":"12458545381722168229"}},"outputId":"21ba8326-994b-422c-c918-5e93450b62c8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Initializing Agentic RAG system...\n","[Embedding Agent] Using device: cpu\n","[Orchestration Agent] Registered Embedding Agent\n","[Orchestration Agent] Registered Retrieval Agent\n","[Orchestration Agent] Registered Transcript Agent\n","[Orchestration Agent] Registered LLM Agent\n","[Orchestration Agent] Registered Formatting Agent\n","AgenticRAGSystem initialized with 5 specialized agents\n","\n","Processing query: 'What is JVM?' with video ID: NUy_wOxOM8E\n","[Orchestration Agent] Starting workflow for question: 'What is JVM?' with video ID: NUy_wOxOM8E\n","[Transcript Agent] Fetching transcript for video: NUy_wOxOM8E\n","[Transcript Agent] Successfully extracted transcript (12779 chars)\n","[Embedding Agent] Generating embedding for: What is JVM?...\n","[Retrieval Agent] Querying Pinecone for top 1 matches filtered by video_id: NUy_wOxOM8E\n","[Retrieval Agent] Retrieved 1 relevant chunks\n","[LLM Agent] Generating answer using llama3-70b-8192 for query: What is JVM?\n","[LLM Agent] Successfully generated answer\n","[Formatting Agent] Formatting final response\n","[Orchestration Agent] Workflow completed in 5.83 seconds\n","\n","==================================================\n","QUESTION: What is JVM?\n","\n","ANSWER:\n","**What is JVM (Java Virtual Machine)?**\n","\n","In the context of Java programming, a Java Virtual Machine (JVM) is a crucial concept that plays a vital role in executing Java programs. To establish a solid foundation in Java, it's essential to understand what JVM is and its significance.\n","\n","**Definition:**\n","A Java Virtual Machine (JVM) is a software program that runs Java bytecode on a computer. It's an abstract computing machine that enables Java programs to be executed on any device supporting JVM, without the need for recompilation.\n","\n","**How it works:**\n","When you compile a Java program, the Java compiler (javac) converts the Java source code (.java files) into an intermediate format called bytecode (.class files). This bytecode is not specific to any particular computer architecture and is platform-independent.\n","\n","The JVM takes this bytecode as input, interprets it, and executes it on the underlying computer. This process involves several stages, including:\n","\n","1. **Loading**: The JVM loads the bytecode into memory.\n","2. **Verification**: The JVM checks the bytecode for correctness and ensures it adheres to Java language semantics.\n","3. **Execution**: The JVM executes the bytecode, translating it into machine-specific code that the underlying computer can understand.\n","\n","**Key benefits:**\n","The JVM provides several benefits, including:\n","\n","1. **Platform independence**: Java programs can run on any device that has a JVM, without the need for recompilation.\n","2. **Memory management**: The JVM handles memory allocation and deallocation, reducing the risk of memory-related errors.\n","3. **Security**: The JVM provides a sandboxed environment, which helps prevent malicious code from causing harm to the system.\n","\n","In summary, the JVM is a software program that runs Java bytecode, providing a platform-independent, secure, and efficient way to execute Java programs. Its role is crucial in the Java ecosystem, and understanding its functionality is essential for any aspiring Java developer.\n","\n","TOP SOURCE:\n","Score: 0.56\n","Video ID: NUy_wOxOM8E\n","Text: hello I'm Jason with code learner calm welcome to mastering Java here we're going to talk about Java terminology we really need to build a foundation on some common terms because if I just jump right into writing code with you then I start talking about methods and classes and you know Java virtual machines and other things if you don't know what those things are then and you're just going to be confused and there's no reason for that because all of the java terminology that you need to know is ...\n","\n","VIDEO TRANSCRIPT EXCERPT:\n","hello I'm Jason with code learner calm. welcome to mastering Java here we're. going to talk about Java terminology we. really need to build a foundation on. some common terms because if I just jump. right into writing code with you then I. start talking about methods and classes. and you know Java virtual machines and. other things if you don't know what. those things are then and you're just. going to be confused and there's no. reason for that because all of the java. terminology that you need...\n","\n","==================================================\n","\n","Process Timing:\n","  embedding_time: 3.99 seconds\n","  retrieval_time: 0.33 seconds\n","  transcript_time: 0.00 seconds\n","  llm_time: 1.51 seconds\n","  total_time: 5.83 seconds\n"]}],"source":["import os\n","import re\n","import numpy as np\n","import pinecone\n","from sentence_transformers import SentenceTransformer\n","from groq import Groq\n","import torch\n","from typing import List, Dict, Any, Optional, Tuple\n","from youtube_transcript_api import YouTubeTranscriptApi\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","import spacy\n","import json\n","import time\n","from concurrent.futures import ThreadPoolExecutor, as_completed\n","\n","class Agent:\n","    \"\"\"Base class for all agents in the system\"\"\"\n","    def __init__(self, name: str):\n","        self.name = name\n","\n","    def process(self, *args, **kwargs):\n","        \"\"\"Process method to be implemented by each agent\"\"\"\n","        raise NotImplementedError(\"Each agent must implement a process method\")\n","\n","    def log(self, message: str):\n","        \"\"\"Simple logging method\"\"\"\n","        print(f\"[{self.name}] {message}\")\n","\n","class EmbeddingAgent(Agent):\n","    \"\"\"Agent responsible for text embeddings and preprocessing\"\"\"\n","    def __init__(self, model_name: str = \"sentence-transformers/all-mpnet-base-v2\"):\n","        super().__init__(\"Embedding Agent\")\n","\n","        # Check for GPU availability\n","        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","        self.log(f\"Using device: {self.device}\")\n","\n","        # Initialize embedding model\n","        self.embedding_model = SentenceTransformer(model_name).to(self.device)\n","\n","        # Initialize NLP tools with better error handling\n","        try:\n","            nltk.download('stopwords', quiet=True)\n","            nltk.download('wordnet', quiet=True)\n","            self.stop_words = set(stopwords.words('english'))\n","            self.lemmatizer = WordNetLemmatizer()\n","        except Exception as e:\n","            self.log(f\"Warning: NLTK resource download issue. Error: {e}\")\n","            self.stop_words = {'a', 'an', 'the', 'and', 'or', 'but', 'is', 'are', 'was', 'were', 'to', 'of', 'in', 'for'}\n","            self.lemmatizer = None\n","\n","        # Load spaCy model with fallback\n","        try:\n","            self.nlp = spacy.load(\"en_core_web_sm\")\n","        except:\n","            self.log(\"Warning: spaCy model 'en_core_web_sm' not found. Using a simple pipeline.\")\n","            self.nlp = spacy.blank(\"en\")\n","\n","    def simple_tokenize(self, text):\n","        \"\"\"Simple tokenizer that avoids NLTK's punkt.\"\"\"\n","        text = re.sub(r'[^\\w\\s]', ' ', text)\n","        return [token for token in text.lower().split() if token]\n","\n","    def preprocess_text(self, text):\n","        \"\"\"NLP preprocessing: stopword removal, lemmatization.\"\"\"\n","        if not text or not isinstance(text, str):\n","            return \"\", {}\n","\n","        text = re.sub(r'[^\\w\\s]', ' ', text).lower()\n","        tokens = self.simple_tokenize(text)\n","        filtered_tokens = [word for word in tokens if word not in self.stop_words]\n","\n","        # Use lemmatizer if available\n","        if self.lemmatizer:\n","            lemmatized_tokens = [self.lemmatizer.lemmatize(word) for word in filtered_tokens]\n","        else:\n","            lemmatized_tokens = filtered_tokens\n","\n","        processed_text = ' '.join(lemmatized_tokens)\n","        return processed_text, {}\n","\n","    def process(self, text: str) -> List[float]:\n","        \"\"\"Generate embedding for the given text.\"\"\"\n","        if not text or not isinstance(text, str):\n","            self.log(\"Warning: Empty or invalid text received for embedding\")\n","            return [0.0] * self.embedding_model.get_sentence_embedding_dimension()\n","\n","        # Apply preprocessing\n","        processed_text, _ = self.preprocess_text(text)\n","\n","        # Ensure we have text to embed\n","        if not processed_text:\n","            processed_text = text  # Fall back to original text\n","\n","        # Generate and return embedding\n","        self.log(f\"Generating embedding for: {text[:50]}...\")\n","        return self.embedding_model.encode(processed_text).tolist()\n","\n","class RetrievalAgent(Agent):\n","    \"\"\"Agent responsible for retrieving relevant information from the vector database\"\"\"\n","    def __init__(self, pinecone_api_key: str, index_name: str):\n","        super().__init__(\"Retrieval Agent\")\n","\n","        # Initialize Pinecone client\n","        self.pc = pinecone.Pinecone(api_key=pinecone_api_key)\n","        self.index = self.pc.Index(index_name)\n","\n","    def process(self, query_embedding: List[float], top_k: int = 1,\n","                video_id: Optional[str] = None) -> List[Dict[str, Any]]:\n","        \"\"\"\n","        Retrieve the most relevant chunks from Pinecone based on the query embedding.\n","        Optionally filter by video ID.\n","        \"\"\"\n","        # Prepare query parameters\n","        query_params = {\n","            \"vector\": query_embedding,\n","            \"top_k\": top_k,\n","            \"include_metadata\": True\n","        }\n","\n","        # Add video ID filter if provided\n","        if video_id:\n","            query_params[\"filter\"] = {\"video_id\": video_id}\n","\n","        # Query Pinecone index using similarity search\n","        try:\n","            self.log(f\"Querying Pinecone for top {top_k} matches\" +\n","                    (f\" filtered by video_id: {video_id}\" if video_id else \"\"))\n","            query_response = self.index.query(**query_params)\n","        except Exception as e:\n","            self.log(f\"Error querying Pinecone: {e}\")\n","            return []\n","\n","        # Extract matches with their metadata\n","        matches = query_response.get('matches', [])\n","\n","        # Format results\n","        results = []\n","        for match in matches:\n","            # Extract text sample from metadata if available\n","            text = match.metadata.get('text_sample', 'No text available')\n","\n","            # Format the result\n","            result = {\n","                'id': match.id,\n","                'score': match.score,\n","                'text': text,\n","                'video_id': match.metadata.get('video_id', 'unknown'),\n","                'chunk_id': match.metadata.get('chunk_id', -1)\n","            }\n","            results.append(result)\n","\n","        self.log(f\"Retrieved {len(results)} relevant chunks\")\n","        return results\n","\n","class TranscriptAgent(Agent):\n","    \"\"\"Agent responsible for extracting and processing YouTube transcripts\"\"\"\n","    def __init__(self):\n","        super().__init__(\"Transcript Agent\")\n","\n","    def process(self, video_id: str) -> Optional[str]:\n","        \"\"\"\n","        Extract transcript from a YouTube video.\n","\n","        Args:\n","            video_id: YouTube video ID\n","\n","        Returns:\n","            Transcript text or None if extraction fails\n","        \"\"\"\n","        if not video_id or not isinstance(video_id, str):\n","            self.log(\"Invalid video ID provided\")\n","            return None\n","\n","        try:\n","            self.log(f\"Fetching transcript for video: {video_id}\")\n","            transcript_list = YouTubeTranscriptApi.get_transcript(video_id)\n","            if not transcript_list:\n","                self.log(f\"No transcript found for video {video_id}\")\n","                return None\n","\n","            # Ensure proper formatting with punctuation\n","            formatted_segments = []\n","            for segment in transcript_list:\n","                text = segment.get('text', '').strip()\n","                if text:\n","                    # Add period if segment doesn't end with punctuation\n","                    if not text[-1] in ['.', '!', '?', ':', ';']:\n","                        text += '.'\n","                    formatted_segments.append(text)\n","\n","            full_transcript = ' '.join(formatted_segments)\n","            self.log(f\"Successfully extracted transcript ({len(full_transcript)} chars)\")\n","            return full_transcript\n","        except Exception as e:\n","            self.log(f\"Error fetching transcript for video {video_id}: {e}\")\n","            return None\n","\n","class LLMAgent(Agent):\n","    \"\"\"Agent responsible for generating answers using an LLM\"\"\"\n","    def __init__(self, groq_api_key: str, model_name: str = \"llama3-70b-8192\"):\n","        super().__init__(\"LLM Agent\")\n","        # Initialize Groq client\n","        self.groq_client = Groq(api_key=groq_api_key)\n","        self.model_name = model_name\n","\n","    def process(self, query: str, relevant_chunks: List[Dict[str, Any]],\n","               transcript: Optional[str] = None) -> Dict[str, Any]:\n","        \"\"\"\n","        Generate a comprehensive answer using Groq's language model based on the query and relevant chunks.\n","        \"\"\"\n","        if not relevant_chunks and not transcript:\n","            self.log(\"No information available to answer the query\")\n","            return {\n","                \"answer\": \"I couldn't find sufficient information to answer your question. Please try rephrasing or asking a different question.\",\n","                \"success\": False\n","            }\n","\n","        # Prepare context from relevant chunks\n","        chunk_context = \"\"\n","        if relevant_chunks:\n","            # Use the top (most relevant) chunk\n","            top_chunk = relevant_chunks[0]\n","            chunk_context = top_chunk['text']\n","\n","        # Add transcript excerpt if available\n","        transcript_context = \"\"\n","        if transcript:\n","            # Use first 1000 characters of transcript\n","            transcript_context = transcript[:1000] + \"...\" if len(transcript) > 1000 else transcript\n","\n","        # Combine contexts\n","        full_context = chunk_context\n","        if transcript_context and not chunk_context:\n","            full_context = transcript_context\n","        elif transcript_context:\n","            full_context += f\"\\n\\nAdditional context from video transcript:\\n{transcript_context}\"\n","\n","        # Prepare a focused prompt for the Groq language model\n","        prompt = f\"\"\"\n","        You are an intelligent assistant specialized in educational content. Your task is to create a comprehensive, well-structured answer to the user's question using the provided context.\n","\n","        USER QUESTION:\n","        {query}\n","\n","        RELEVANT CONTEXT:\n","        {full_context}\n","        \"\"\"\n","\n","        # Use Groq's chat completion API\n","        try:\n","            self.log(f\"Generating answer using {self.model_name} for query: {query}\")\n","            response = self.groq_client.chat.completions.create(\n","                model=self.model_name,\n","                messages=[\n","                    {\"role\": \"system\", \"content\": \"You are an intelligent assistant specialized in educational content.\"},\n","                    {\"role\": \"user\", \"content\": prompt}\n","                ],\n","                max_tokens=512,\n","                temperature=0.7,\n","                top_p=0.95\n","            )\n","\n","            # Extract the answer from the response\n","            answer = response.choices[0].message.content.strip()\n","\n","            self.log(\"Successfully generated answer\")\n","            return {\n","                \"answer\": answer,\n","                \"success\": True\n","            }\n","\n","        except Exception as e:\n","            self.log(f\"Error generating answer with Groq: {e}\")\n","            return {\n","                \"answer\": \"I encountered an error while generating the answer. Please try again.\",\n","                \"success\": False\n","            }\n","\n","class FormattingAgent(Agent):\n","    \"\"\"Agent responsible for formatting responses and results\"\"\"\n","    def __init__(self):\n","        super().__init__(\"Formatting Agent\")\n","\n","    def process(self, result: Dict[str, Any]) -> str:\n","        \"\"\"\n","        Format the query result into a well-structured response string.\n","        \"\"\"\n","        self.log(\"Formatting final response\")\n","        response = f\"QUESTION: {result['question']}\\n\\nANSWER:\\n{result['answer']}\\n\\n\"\n","\n","        if result.get('source'):\n","            source = result['source']\n","            response += \"TOP SOURCE:\\n\"\n","            response += f\"Score: {source['score']:.2f}\\n\"\n","            response += f\"Video ID: {source['video_id']}\\n\"\n","            response += f\"Text: {source['text']}\\n\"\n","\n","        # Add video transcript if available\n","        if result.get('video_transcript'):\n","            response += \"\\nVIDEO TRANSCRIPT EXCERPT:\\n\"\n","            # Limit transcript to first 500 characters\n","            transcript_excerpt = result['video_transcript'][:500] + \"...\"\n","            response += transcript_excerpt + \"\\n\"\n","\n","        return response\n","\n","class OrchestrationAgent(Agent):\n","    \"\"\"Agent responsible for orchestrating the overall workflow\"\"\"\n","    def __init__(self):\n","        super().__init__(\"Orchestration Agent\")\n","        self.agents = {}\n","        self.executor = ThreadPoolExecutor(max_workers=3)\n","\n","    def register_agent(self, agent_type: str, agent: Agent):\n","        \"\"\"Register an agent to be used in the workflow\"\"\"\n","        self.agents[agent_type] = agent\n","        self.log(f\"Registered {agent.name}\")\n","\n","    def process(self, question: str, video_id: Optional[str] = None) -> Dict[str, Any]:\n","        \"\"\"\n","        Orchestrate the entire workflow to process a user query\n","        \"\"\"\n","        start_time = time.time()\n","        self.log(f\"Starting workflow for question: '{question}'\" +\n","                (f\" with video ID: {video_id}\" if video_id else \"\"))\n","\n","        # Track workflow metrics\n","        metrics = {\n","            \"embedding_time\": 0,\n","            \"retrieval_time\": 0,\n","            \"transcript_time\": 0,\n","            \"llm_time\": 0,\n","            \"total_time\": 0\n","        }\n","\n","        # Step 1: Launch transcript extraction if video_id is provided (async)\n","        transcript_future = None\n","        if video_id:\n","            transcript_future = self.executor.submit(self.agents[\"transcript\"].process, video_id)\n","\n","        # Step 2: Generate embedding for the question\n","        embedding_start = time.time()\n","        query_embedding = self.agents[\"embedding\"].process(question)\n","        metrics[\"embedding_time\"] = time.time() - embedding_start\n","\n","        # Step 3: Retrieve relevant chunks\n","        retrieval_start = time.time()\n","        relevant_chunks = self.agents[\"retrieval\"].process(\n","            query_embedding,\n","            top_k=1,\n","            video_id=video_id\n","        )\n","        metrics[\"retrieval_time\"] = time.time() - retrieval_start\n","\n","        # If no chunks found and a video ID was provided, try without the filter\n","        if not relevant_chunks and video_id:\n","            self.log(\"No matches with video filter, trying without filter\")\n","            relevant_chunks = self.agents[\"retrieval\"].process(query_embedding, top_k=1)\n","\n","        # Wait for transcript result if we started one\n","        transcript = None\n","        if transcript_future:\n","            transcript_start = time.time()\n","            try:\n","                transcript = transcript_future.result(timeout=10)  # Wait up to 10 seconds\n","            except Exception as e:\n","                self.log(f\"Error waiting for transcript: {e}\")\n","            metrics[\"transcript_time\"] = time.time() - transcript_start\n","\n","        # Step 4: Generate answer\n","        llm_start = time.time()\n","        answer_result = self.agents[\"llm\"].process(question, relevant_chunks, transcript)\n","        metrics[\"llm_time\"] = time.time() - llm_start\n","\n","        # Step 5: Prepare final result\n","        result = {\n","            \"question\": question,\n","            \"answer\": answer_result[\"answer\"],\n","            \"source\": relevant_chunks[0] if relevant_chunks else None,\n","            \"video_id\": video_id,\n","            \"video_transcript\": transcript,\n","            \"success\": answer_result[\"success\"],\n","            \"metrics\": metrics\n","        }\n","\n","        # Step 6: Format the response\n","        formatted_response = self.agents[\"formatting\"].process(result)\n","        result[\"formatted_response\"] = formatted_response\n","\n","        # Calculate total processing time\n","        metrics[\"total_time\"] = time.time() - start_time\n","        self.log(f\"Workflow completed in {metrics['total_time']:.2f} seconds\")\n","\n","        return result\n","\n","class AgenticRAGSystem:\n","    \"\"\"Main class for the Agentic RAG System, integrating all agents\"\"\"\n","    def __init__(self, pinecone_api_key: str, groq_api_key: str, index_name: str,\n","                 model_name: str = \"sentence-transformers/all-mpnet-base-v2\",\n","                 llm_model: str = \"llama3-70b-8192\"):\n","        \"\"\"\n","        Initialize Agentic RAG system with all required agents\n","        \"\"\"\n","        # Create all agents\n","        self.embedding_agent = EmbeddingAgent(model_name)\n","        self.retrieval_agent = RetrievalAgent(pinecone_api_key, index_name)\n","        self.transcript_agent = TranscriptAgent()\n","        self.llm_agent = LLMAgent(groq_api_key, llm_model)\n","        self.formatting_agent = FormattingAgent()\n","\n","        # Create and configure orchestration agent\n","        self.orchestrator = OrchestrationAgent()\n","        self.orchestrator.register_agent(\"embedding\", self.embedding_agent)\n","        self.orchestrator.register_agent(\"retrieval\", self.retrieval_agent)\n","        self.orchestrator.register_agent(\"transcript\", self.transcript_agent)\n","        self.orchestrator.register_agent(\"llm\", self.llm_agent)\n","        self.orchestrator.register_agent(\"formatting\", self.formatting_agent)\n","\n","        print(f\"AgenticRAGSystem initialized with {len(self.orchestrator.agents)} specialized agents\")\n","\n","    def query(self, question: str, video_id: Optional[str] = None) -> Dict[str, Any]:\n","        \"\"\"\n","        Process a user query using the agentic workflow\n","        \"\"\"\n","        # Delegate to the orchestrator\n","        return self.orchestrator.process(question, video_id)\n","\n","    def format_response(self, result: Dict[str, Any]) -> str:\n","        \"\"\"\n","        Return the formatted response from the result\n","        \"\"\"\n","        return result.get(\"formatted_response\", \"No formatted response available\")\n","\n","# Example usage\n","def main():\n","    # Initialize the Agentic RAG system\n","    pinecone_api_key = \"pcsk_7EKroD_MaZi2zjikyZTdpaDPCkit4qEAE6cjKuJ7C2ot9htS7EE6uurWQLrfznykMd7bW3\"\n","    groq_api_key = \"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\"\n","    index_name = \"embeddings\"\n","\n","    print(\"Initializing Agentic RAG system...\")\n","    rag = AgenticRAGSystem(\n","        pinecone_api_key=pinecone_api_key,\n","        groq_api_key=groq_api_key,\n","        index_name=index_name,\n","        model_name=\"sentence-transformers/all-mpnet-base-v2\",\n","        llm_model=\"llama3-70b-8192\"\n","    )\n","\n","    # Example query with video ID\n","    question = \"What is JVM?\"\n","    video_id = \"NUy_wOxOM8E\"  # Example YouTube video ID\n","\n","    # Add error handling around the main query operation\n","    try:\n","        print(f\"\\nProcessing query: '{question}' with video ID: {video_id}\")\n","        result = rag.query(question, video_id)\n","\n","        # Print the formatted result\n","        print(\"\\n\" + \"=\"*50)\n","        print(result[\"formatted_response\"])\n","        print(\"=\"*50)\n","\n","        # Print timing metrics\n","        print(\"\\nProcess Timing:\")\n","        for key, value in result[\"metrics\"].items():\n","            print(f\"  {key}: {value:.2f} seconds\")\n","\n","    except Exception as e:\n","        print(f\"An error occurred during query processing: {e}\")\n","\n","if __name__ == \"__main__\":\n","    main()"]},{"cell_type":"code","source":[],"metadata":{"id":"o4I9nuOFoUgZ"},"execution_count":null,"outputs":[]}]}